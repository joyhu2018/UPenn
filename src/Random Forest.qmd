---
title: "Random Forest"
format: html
---

## Random Forest

We first load in necessary data frames. We will use `cv_data` to train and test our Random Forest model.

```{r r Setup, include=FALSE, results='hide', warning=FALSE}
knitr::opts_chunk$set(echo = F, fig.width=8, fig.height=4, warning = F)
options(scipen = 0, digits = 3)  ## controls base R output

## Package setup
if(!require("pacman")) install.packages("pacman")

pacman::p_load(tidyverse, dplyr, ggplot2, data.table, lubridate, plotROC, usmap, glmnet, knitr, xtable, vader, randomForest, tree, ISLR, rpart, ranger, rattle, pROC, partykit, lda, stargazer, gridExtra, caret, rpart.plot)
```

```{r loading in data sets}
allcombined <- read.csv("/Users/joy/Desktop/UPenn/data/allcombined.csv", header = TRUE, stringsAsFactors = FALSE)
cv_data <- read.csv("/Users/joy/Desktop/UPenn/data/cv_data.csv", header = TRUE, stringsAsFactors = FALSE)
valid_data <- read.csv("/Users/joy/Desktop/UPenn/data/valid_data.csv", header = TRUE, stringsAsFactors = FALSE)
```

First, we try a single tree with all variables named `fitsingletree`.

```{r}
cv_short <- cv_data %>% select(-retweetCount, - id, -text, -datetime)

fitsinglerp <- rpart(likeCount10k ~ ., data = cv_short, minsplit=2, cp=.009)

plot(as.party(fitsinglerp), main="A Tree with Rpart")

rpart.plot(fitsinglerp, type = 2, fallen.leaves = TRUE,
main = "RPart Single Decision Tree")

 
```

After seeing what a single tree looks like, we create a random forest named `fitrf`. We remove some variables because they are purely for identification purposes (`id`, `text`, `datetime`) or because they are also dependent variables (`retweetCount`).

```{r}
#ncol(cv_data) #seeing how many variables
set.seed(1)
fitrf <- randomForest(likeCount10k ~ .,data = cv_short, mtry=37, ntree=250)

#summary(fitrf)
```

Before we finalize our model, we want to optimize and tune our `mtry` and `ntree` values.

```{r}
#tuning ntree
fitrf.tune <- randomForest(likeCount10k~., data = cv_short, mtry=7, ntree=100) # change ntree 
plot(fitrf.tune, col="red", pch=16, type="p",
main="Random Forest testing error")

#tuning mtry
rf.error.p <- 1:37
for (p in 1:37)  
  {fit.rf <- randomForest(likeCount10k~., data = cv_short, mtry=p, ntree=100) #plot(fit.rf, col= p, lwd = 3)
rf.error.p[p] <- fit.rf$mse[100]
}
rf.error.p

#visualizing mtry
plot(1:37, rf.error.p, pch=16,
main = "Testing errors of mtry with 200 trees", xlab="mtry",
ylab="mse of mtry")
lines(1:37, rf.error.p)
```

The graph for `ntree` levels around 100, which should be the optimal `ntree`. Based on the graph, `mtry` should be 7. But, we will choose `mtry`=7 for simplicity and efficiency. Now, we construct our final model.

```{r}
fitrf.final <- randomForest(likeCount10k~., data = cv_short, mtry=7, ntree=100) 
plot(fitrf.final)
```

Finally, we will use `valid_data` to test the error of our final model `fitrf.final`.

```{r}
fitrf.final.pred <- predict(fitrf.final, valid_data)
error_fitrf.final <- mean((valid_data$likeCount10k - fitrf.final.pred)^2)
error_fitrf.final



plot(fitrf.final, type="p", pch=16,col="blue", main = "fitrf.final testing errors" )

```
